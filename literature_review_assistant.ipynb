{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lisammi/Desktop/llmor/.venv/lib/python3.9/site-packages/pydantic/_internal/_config.py:345: UserWarning: Valid config keys have changed in V2:\n",
      "* 'fields' has been removed\n",
      "  warnings.warn(message, UserWarning)\n",
      "/Users/lisammi/Desktop/llmor/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import langchain, langgraph, dspy, openai, chromadb, streamlit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import UnstructuredWordDocumentLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "import requests\n",
    "from langchain.agents import Tool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "import arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "# Set your OpenAI API key on the module\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Create a chat completion using the GPT-3.5-turbo model\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello, world!\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the content of the first message in the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Task 1: Summarize offline PDFs that contain some research abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lb/_r77cfp52216j6zh_x2jdhk00000gn/T/ipykernel_53770/3971832814.py:14: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings()\n",
      "/var/folders/lb/_r77cfp52216j6zh_x2jdhk00000gn/T/ipykernel_53770/3971832814.py:18: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(temperature=0)\n",
      "/var/folders/lb/_r77cfp52216j6zh_x2jdhk00000gn/T/ipykernel_53770/3971832814.py:23: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  answer = qa.run(query)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_670f0_row0_col0, #T_670f0_row0_col1, #T_670f0_row1_col0, #T_670f0_row1_col1, #T_670f0_row2_col0, #T_670f0_row2_col1, #T_670f0_row3_col0, #T_670f0_row3_col1, #T_670f0_row4_col0, #T_670f0_row4_col1 {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_670f0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_670f0_level0_col0\" class=\"col_heading level0 col0\" >Title</th>\n",
       "      <th id=\"T_670f0_level0_col1\" class=\"col_heading level0 col1\" >Summary and Insights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_670f0_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_670f0_row0_col0\" class=\"data row0 col0\" >Abstract 1.pdf</td>\n",
       "      <td id=\"T_670f0_row0_col1\" class=\"data row0 col1\" >The study presents an integrated operations research framework for optimizing<br>urban bike lane design, considering factors such as connectivity, accident<br>risk minimization, and cost constraints. The approach uses network analysis<br>techniques and simulation-based validation to capture dynamic interactions between cyclists,<br>motor vehicles, and pedestrians. The case study showed that optimal<br>reconfiguration of bike lanes can reduce travel times and improve<br>safety metrics by over 20%, providing actionable insights for urban<br>planners and policymakers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_670f0_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_670f0_row1_col0\" class=\"data row1 col0\" >Abstract 2.pdf</td>\n",
       "      <td id=\"T_670f0_row1_col1\" class=\"data row1 col1\" >The paper presents a novel mixed integer programming formulation for<br>multi-modal transportation network design under uncertainty. The model integrates discrete<br>and continuous variables and incorporates robustness against demand fluctuations. Advanced<br>decomposition algorithms and cutting-plane methods are used to efficiently solve<br>large-scale instances. Computational experiments show that the approach outperforms traditional<br>heuristics, achieving cost reduction and improved network reliability. The paper<br>offers a versatile decision-support tool for transportation planners facing complex<br>trade-offs in system design.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_670f0_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_670f0_row2_col0\" class=\"data row2 col0\" >Abstract 3.pdf</td>\n",
       "      <td id=\"T_670f0_row2_col1\" class=\"data row2 col1\" >The paper introduces an advanced mixed logit model to capture<br>heterogeneous preferences in urban travel mode choice, with an emphasis<br>on incorporating unobserved factors. The model allows for random taste<br>variations and flexible substitution patterns among alternatives. The estimation is<br>carried out using simulated maximum likelihood methods on a comprehensive<br>dataset. The empirical results show significant variabilities in sensitivity to<br>travel time and cost across demographic segments, providing insights into<br>modal shifts in response to policy interventions. These findings have<br>implications for targeted investments in public transit and non-motorized transportation<br>infrastructure.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_670f0_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_670f0_row3_col0\" class=\"data row3 col0\" >Abstract 4.pdf</td>\n",
       "      <td id=\"T_670f0_row3_col1\" class=\"data row3 col1\" >The paper proposes a methodology for evaluating operational improvements in<br>dynamic service systems, which involves using fractional factorial designs and<br>sequential testing procedures. Through experiments in a simulated call center<br>environment, the paper demonstrates the effectiveness of this approach in<br>identifying key process parameters that influence system performance. The optimized<br>configurations can reduce customer wait times by up to 30%<br>while maintaining cost efficiency. This paper provides a blueprint for<br>practitioners looking to implement evidence-based improvements in complex operational settings.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_670f0_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_670f0_row4_col0\" class=\"data row4 col0\" >Abstract 5.pdf</td>\n",
       "      <td id=\"T_670f0_row4_col1\" class=\"data row4 col1\" >The research paper develops an optimization framework using techniques from<br>operations research and queuing theory to improve patient flow and<br>resource allocation in hospital emergency departments. The model incorporates real-time<br>data and is solved using a combination of heuristic and<br>exact algorithms. Simulation studies using hospital data show that the<br>approach can improve throughput by 25% and reduce critical delays,<br>ultimately enhancing overall patient outcomes. This study offers a practical<br>tool for healthcare administrators to optimize emergency care in varying<br>demand conditions.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb593447e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "pdf_files = [\"Abstract 1.pdf\", \"Abstract 2.pdf\", \"Abstract 3.pdf\", \"Abstract 4.pdf\", \"Abstract 5.pdf\"]\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "results = []\n",
    "\n",
    "for doc in pdf_files:\n",
    "    # Step 1: Load the PDF Document\n",
    "    pdf_path = doc\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # Step 2: Create Embeddings and Build a Vector Store\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "    # Step 3: Set Up a RetrievalQA Chain\n",
    "    llm = OpenAI(temperature=0)\n",
    "    qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=vectorstore.as_retriever())\n",
    "    \n",
    "    # Step 4: Query the PDFs\n",
    "    query = \"Summarize the methodologies and key insights from these papers.\"\n",
    "    answer = qa.run(query)\n",
    "    \n",
    "    # Append the result with Title and Summary/Insights only\n",
    "    results.append([doc, answer])\n",
    "\n",
    "# Create a DataFrame from the results with only two columns\n",
    "df_results = pd.DataFrame(results, columns=[\"Title\", \"Summary and Insights\"])\n",
    "\n",
    "# Function to format the answer into multiple lines\n",
    "def format_answer(answer, max_line_length=80):\n",
    "    words = answer.split()\n",
    "    formatted_answer = \"\"\n",
    "    current_line = \"\"\n",
    "    \n",
    "    for word in words:\n",
    "        if len(current_line) + len(word) + 1 <= max_line_length:\n",
    "            current_line += \" \" + word\n",
    "        else:\n",
    "            formatted_answer += current_line.strip() + \"\\n\"\n",
    "            current_line = word\n",
    "    \n",
    "    formatted_answer += current_line.strip()\n",
    "    return formatted_answer\n",
    "\n",
    "# Apply formatting to the \"Summary and Insights\" column\n",
    "df_results[\"Summary and Insights\"] = df_results[\"Summary and Insights\"].apply(format_answer)\n",
    "\n",
    "def wrap_text_with_br(text, words_per_line=10):\n",
    "    words = text.split()\n",
    "    lines = []\n",
    "    for i in range(0, len(words), words_per_line):\n",
    "        lines.append(\" \".join(words[i : i + words_per_line]))\n",
    "    # Join lines with <br> for HTML line breaks\n",
    "    return \"<br>\".join(lines)\n",
    "\n",
    "df_results[\"Summary and Insights\"] = df_results[\"Summary and Insights\"].apply(\n",
    "    lambda x: wrap_text_with_br(x, words_per_line=10)\n",
    ")\n",
    "\n",
    "# Tell Pandas to use 'pre-wrap' so it respects line breaks\n",
    "df_styled = df_results.style.set_properties(**{\n",
    "    'white-space': 'pre-wrap',\n",
    "    'word-wrap': 'break-word'\n",
    "})\n",
    "\n",
    "display(df_styled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Task 2: Find the document that is most relevant to indicated topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lb/_r77cfp52216j6zh_x2jdhk00000gn/T/ipykernel_53770/3871060482.py:37: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  answer = llm(prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Most Relevant Paper Explanation ===\n",
      "\n",
      "Paper: Abstract 1.pdf\n",
      "\n",
      "The paper titled \"Abstract 1.pdf\" is most relevant to the topic of optimization because it presents an integrated operations research\n",
      "framework for optimizing urban bike lane design, considering factors such as connectivity, accident risk minimization, and cost constraints in a\n",
      "congested urban setting, and using network analysis techniques and simulation-based validation to capture dynamic interactions between cyclists, motor vehicles, and\n",
      "pedestrians. The paper also provides a case study that demonstrates how the optimal reconfiguration of bike lanes can improve safety\n",
      "metrics and reduce travel times by over 20%, providing actionable insights for urban planners and policymakers aiming to foster sustainable\n",
      "and resilient transportation networks.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Load All PDFs and Add Metadata ---\n",
    "documents = []\n",
    "for pdf in pdf_files:\n",
    "    loader = PyPDFLoader(pdf)\n",
    "    docs = loader.load()\n",
    "    # Add the file name as metadata (this will serve as the paper title)\n",
    "    for doc in docs:\n",
    "        doc.metadata[\"source\"] = pdf\n",
    "    documents.extend(docs)\n",
    "\n",
    "# --- Step 2: Create Embeddings and Build a Vector Store ---\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "# --- Step 3: Retrieve the Most Relevant Document ---\n",
    "# Perform a similarity search with k=1 to get the top result for \"optimization\"\n",
    "query = \"optimization\"\n",
    "retrieved_docs = vectorstore.similarity_search(query, k=1)\n",
    "top_doc = retrieved_docs[0]\n",
    "paper_title = top_doc.metadata.get(\"source\", \"Unknown\")\n",
    "abstract_text = top_doc.page_content\n",
    "\n",
    "# --- Step 4: Use the LLM to Explain the Relevance ---\n",
    "# Construct a prompt that includes the paper title and abstract text\n",
    "llm = OpenAI(temperature=0)\n",
    "prompt = f\"\"\"\n",
    "You are an academic research assistant.\n",
    "Below is the abstract from a paper titled \"{paper_title}\".\n",
    "Based on this abstract, explain why this paper is most relevant to the topic of optimization.\n",
    "Please include your reasoning, the paper title, and a brief explanation in one sentence.\n",
    "\n",
    "Abstract:\n",
    "{abstract_text}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "answer = llm(prompt)\n",
    "\n",
    "# Helper function to wrap text every 20 words\n",
    "def wrap_text(text, words_per_line=20):\n",
    "    words = text.split()\n",
    "    lines = []\n",
    "    for i in range(0, len(words), words_per_line):\n",
    "        lines.append(\" \".join(words[i:i+words_per_line]))\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "formatted_answer = wrap_text(answer, words_per_line=20)\n",
    "\n",
    "print(\"\\n=== Most Relevant Paper Explanation ===\\n\")\n",
    "print(f\"Paper: {paper_title}\\n\")\n",
    "print(formatted_answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Task 3: Compare the documents and rank them by similarity scores that is calculate by how related they are with the indicated topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Similarity Scores and Summaries for Each Paper ===\n",
      "\n",
      "Paper file: Abstract 1.pdf\n",
      "Similarity Score (lower is more similar): 0.31733963\n",
      "Summary: An integrated operations research framework can optimize urban bike lane design to improve safety and traffic efficiency, with a case study showing potential for significant improvements.\n",
      "--------------------------------------------------------------------------------\n",
      "Paper file: Abstract 2.pdf\n",
      "Similarity Score (lower is more similar): 0.47546792\n",
      "Summary: A novel MIP formulation for multi-modal transportation network design under uncertainty that outperforms traditional heuristics and offers a versatile decision-support tool for transportation planners.\n",
      "--------------------------------------------------------------------------------\n",
      "Paper file: Abstract 3.pdf\n",
      "Similarity Score (lower is more similar): 0.4773534\n",
      "Summary: An advanced mixed logit model is used to analyze urban travel mode choice, revealing significant variations in preferences and providing insights for targeted transportation investments.\n",
      "--------------------------------------------------------------------------------\n",
      "Paper file: Abstract 4.pdf\n",
      "Similarity Score (lower is more similar): 0.55805117\n",
      "Summary: A methodology for evaluating operational improvements in dynamic service systems using fractional factorial designs and sequential testing procedures can significantly reduce customer wait times while maintaining cost efficiency.\n",
      "--------------------------------------------------------------------------------\n",
      "Paper file: Abstract 5.pdf\n",
      "Similarity Score (lower is more similar): 0.57581234\n",
      "Summary: An optimization framework using operations research and queuing theory can improve patient outcomes and reduce costs in hospital emergency departments.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Load All PDFs with Metadata ---\n",
    "documents = []\n",
    "for pdf in pdf_files:\n",
    "    loader = PyPDFLoader(pdf)\n",
    "    docs = loader.load()\n",
    "    for doc in docs:\n",
    "        # Tag each document with its source (filename)\n",
    "        doc.metadata[\"source\"] = pdf\n",
    "    documents.extend(docs)\n",
    "\n",
    "# --- Step 2: Create Embeddings and Build a Vector Store ---\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "# --- Step 3: Define Your Query and Retrieve Similarity Scores ---\n",
    "topic_query = \"bike planning\"\n",
    "\n",
    "# Retrieve all documents along with their similarity scores.\n",
    "results = vectorstore.similarity_search_with_score(topic_query, k=len(documents))\n",
    "\n",
    "# --- Step 4: Print the Similarity Scores and Summaries for Each Paper ---\n",
    "print(\"\\n=== Similarity Scores and Summaries for Each Paper ===\\n\")\n",
    "for doc, score in results:\n",
    "    # Generate a one-sentence summary using your LLM.\n",
    "    summary_prompt = (\n",
    "        \"Please provide a one-sentence summary that captures the most important \"\n",
    "        \"insight from the following document text:\\n\\n\" + doc.page_content\n",
    "    )\n",
    "    summary_sentence = llm(summary_prompt)\n",
    "    \n",
    "    print(\"Paper file:\", doc.metadata.get(\"source\", \"Unknown\"))\n",
    "    print(\"Similarity Score (lower is more similar):\", score)\n",
    "    print(\"Summary:\", summary_sentence.strip())\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test task 4: Search for papers that are relevant to indicated topics online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lb/_r77cfp52216j6zh_x2jdhk00000gn/T/ipykernel_53770/1871608725.py:69: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I should use INFORMSJournalSearch to find relevant papers.\n",
      "Action: INFORMSJournalSearch\n",
      "Action Input: \"bike lanes planning\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mTitle: Planning Bike Lanes with Data: Ridership, Congestion, and Path Selection\n",
      "Venue: Management Sciences\n",
      "Abstract: Urban infrastructure is vital for sustainable cities. In recent years, municipal governments have invested heavily in the expansion of bike lane networks to meet growing demand, promote ridership, and reduce emissions. However, reallocating road capacity to cycling is often contentious because of the risk of amplifying traffic congestion. In this paper, we develop a method for planning bike lanes that accounts for ridership and congestion effects. We first present a procedure for estimating parameters of a traffic equilibrium model, which combines an inverse optimization method for predicting driving times with an instrumental variables method for estimating a commuter mode choice model. We then formulate a prescriptive model that selects paths in a road network for bike lane installation while endogenizing cycling demand and driving travel times. We conduct an empirical study on the City of Chicago that brings together several data sets that describe the urban environment—including the road and bike lane networks, vehicle flows, commuter mode choices, bike share trips, driving and cycling routes, demographic features, and points of interest—with the goal of estimating the impact of expanding Chicago’s bike lane network. We estimate that adding 25 miles of bike lanes as prescribed by our model can lift cycling ridership from 3.6% to 6.1%, with at most a 9.4% increase in driving times. We also find that three intuitive heuristics for bike lane planning can lead to lower ridership and worse congestion outcomes, highlighting the value of a holistic and data-driven approach to urban infrastructure planning. This paper was accepted by Karan Girotra, operations management. Funding: Funding: The authors acknowledge funding from the UCLA Anderson Easton Technology Management Center (Siddiq & Zhang) and the Natural Sciences and Engineering Research Council of Canada [Grant RGPIN-2022-04950] and TD-MDAL Research Grant from the Rotman School of Management (Liu). Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2022.00775 .\n",
      "URL: https://www.semanticscholar.org/paper/457b68681092baa73e7a5f92c27985a21890465d\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should repeat the INFORMSJournalSearch action with different inputs to find more relevant papers.\n",
      "Action: INFORMSJournalSearch\n",
      "Action Input: \"bike lanes planning\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mError: Received status code 429 from Semantic Scholar API.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should try a different input to avoid the error.\n",
      "Action: INFORMSJournalSearch\n",
      "Action Input: \"bike lane planning\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mError: Received status code 429 from Semantic Scholar API.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should try a more specific input to avoid the error.\n",
      "Action: INFORMSJournalSearch\n",
      "Action Input: \"bike lane planning\" AND \"urban infrastructure\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mTitle: Urban Bike Lane Planning with Bike Trajectories: Models, Algorithms, and a Real-World Case Study\n",
      "Venue: Manufacturing & Service Operations Management\n",
      "Abstract: Problem definition: We study an urban bike lane planning problem based on the fine-grained bike trajectory data, which are made available by smart city infrastructure, such as bike-sharing systems. The key decision is where to build bike lanes in the existing road network. Academic/practical relevance: As bike-sharing systems become widespread in the metropolitan areas over the world, bike lanes are being planned and constructed by many municipal governments to promote cycling and protect cyclists. Traditional bike lane planning approaches often rely on surveys and heuristics. We develop a general and novel optimization framework to guide the bike lane planning from bike trajectories. Methodology: We formalize the bike lane planning problem in view of the cyclists’ utility functions and derive an integer optimization model to maximize the utility. To capture cyclists’ route choices, we develop a bilevel program based on the Multinomial Logit model. Results: We derive structural properties about the base model and prove that the Lagrangian dual of the bike lane planning model is polynomial-time solvable. Furthermore, we reformulate the route-choice-based planning model as a mixed-integer linear program using a linear approximation scheme. We develop tractable formulations and efficient algorithms to solve the large-scale optimization problem. Managerial implications: Via a real-world case study with a city government, we demonstrate the efficiency of the proposed algorithms and quantify the trade-off between the coverage of bike trips and continuity of bike lanes. We show how the network topology evolves according to the utility functions and highlight the importance of understanding cyclists’ route choices. The proposed framework drives the data-driven urban-planning scheme in smart city operations management.\n",
      "URL: https://www.semanticscholar.org/paper/c6c1e9db7727b0fc4dbec2e94102826db0fa18dc\n",
      "\n",
      "Title: Planning Bike Lanes with Data: Ridership, Congestion, and Path Selection\n",
      "Venue: Management Sciences\n",
      "Abstract: Urban infrastructure is vital for sustainable cities. In recent years, municipal governments have invested heavily in the expansion of bike lane networks to meet growing demand, promote ridership, and reduce emissions. However, reallocating road capacity to cycling is often contentious because of the risk of amplifying traffic congestion. In this paper, we develop a method for planning bike lanes that accounts for ridership and congestion effects. We first present a procedure for estimating parameters of a traffic equilibrium model, which combines an inverse optimization method for predicting driving times with an instrumental variables method for estimating a commuter mode choice model. We then formulate a prescriptive model that selects paths in a road network for bike lane installation while endogenizing cycling demand and driving travel times. We conduct an empirical study on the City of Chicago that brings together several data sets that describe the urban environment—including the road and bike lane networks, vehicle flows, commuter mode choices, bike share trips, driving and cycling routes, demographic features, and points of interest—with the goal of estimating the impact of expanding Chicago’s bike lane network. We estimate that adding 25 miles of bike lanes as prescribed by our model can lift cycling ridership from 3.6% to 6.1%, with at most a 9.4% increase in driving times. We also find that three intuitive heuristics for bike lane planning can lead to lower ridership and worse congestion outcomes, highlighting the value of a holistic and data-driven approach to urban infrastructure planning. This paper was accepted by Karan Girotra, operations management. Funding: Funding: The authors acknowledge funding from the UCLA Anderson Easton Technology Management Center (Siddiq & Zhang) and the Natural Sciences and Engineering Research Council of Canada [Grant RGPIN-2022-04950] and TD-MDAL Research Grant from the Rotman School of Management (Liu). Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2022.00775 .\n",
      "URL: https://www.semanticscholar.org/paper/457b68681092baa73e7a5f92c27985a21890465d\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should now summarize the key findings and venues of the two papers.\n",
      "Final Answer: The two papers found through INFORMSJournalSearch are \"Planning Bike Lanes with Data: Ridership, Congestion, and Path Selection\" published in Management Sciences and \"Urban Bike Lane Planning with Bike Trajectories: Models, Algorithms, and a Real-World Case Study\" published in Manufacturing & Service Operations Management. Both papers use data-driven approaches to plan bike lanes in urban areas and highlight the importance of considering ridership and congestion effects. The first paper focuses on the City of Chicago and estimates that adding 25 miles of bike lanes can increase cycling ridership by 3.6% to 6.1% with a maximum 9.4% increase in driving times. The second paper presents a general optimization framework and efficient algorithms for bike lane planning based on fine-grained bike trajectory data. It also includes a real-world case study with a city government to demonstrate the effectiveness of the proposed approach.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "=== INFORMS Journal Search Result ===\n",
      "\n",
      "The two papers found through INFORMSJournalSearch are \"Planning Bike Lanes with Data: Ridership, Congestion, and Path Selection\" published in Management Sciences and \"Urban Bike Lane Planning with Bike Trajectories: Models, Algorithms, and a Real-World Case Study\" published in Manufacturing & Service Operations Management. Both papers use data-driven approaches to plan bike lanes in urban areas and highlight the importance of considering ridership and congestion effects. The first paper focuses on the City of Chicago and estimates that adding 25 miles of bike lanes can increase cycling ridership by 3.6% to 6.1% with a maximum 9.4% increase in driving times. The second paper presents a general optimization framework and efficient algorithms for bike lane planning based on fine-grained bike trajectory data. It also includes a real-world case study with a city government to demonstrate the effectiveness of the proposed approach.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Define a Custom Tool to Search INFORMS Journals ---\n",
    "def informs_journal_search(query: str, limit: int = 10) -> str:\n",
    "    \"\"\"\n",
    "    Searches Semantic Scholar for academic papers on the given query,\n",
    "    then filters the results for papers published in known INFORMS journals,\n",
    "    particularly in the domains of Operations Research, Management Science,\n",
    "    MSOM, and other INFORMS outlets.\n",
    "    \"\"\"\n",
    "    # Known INFORMS journals (adjust as needed)\n",
    "    informs_journals = [\n",
    "        \"Management Science\", \n",
    "        \"Operations Research\", \n",
    "        \"Manufacturing & Service Operations Management\",\n",
    "        \"INFORMS Journal on Computing\",\n",
    "        \"INFORMS Journal on Applied Analytics\",\n",
    "        \"Interfaces\",\n",
    "        \"Transportation Science\"\n",
    "    ]\n",
    "    \n",
    "    url = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n",
    "    params = {\n",
    "        \"query\": query,\n",
    "        \"limit\": limit,  # Retrieve a larger set of papers for filtering\n",
    "        \"fields\": \"title,abstract,url,venue\"\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        return f\"Error: Received status code {response.status_code} from Semantic Scholar API.\"\n",
    "    \n",
    "    data = response.json()\n",
    "    papers = data.get(\"data\", [])\n",
    "    if not papers:\n",
    "        return \"No papers found for this query.\"\n",
    "    \n",
    "    # Filter papers whose 'venue' matches any known INFORMS journals.\n",
    "    filtered_papers = []\n",
    "    for paper in papers:\n",
    "        venue = paper.get(\"venue\", \"\")\n",
    "        if any(journal.lower() in venue.lower() for journal in informs_journals):\n",
    "            filtered_papers.append(paper)\n",
    "    \n",
    "    if not filtered_papers:\n",
    "        return \"No INFORMS journal papers found for this query.\"\n",
    "    \n",
    "    results = []\n",
    "    for paper in filtered_papers:\n",
    "        title = paper.get(\"title\", \"No title\")\n",
    "        abstract = paper.get(\"abstract\", \"No abstract available\")\n",
    "        paper_url = paper.get(\"url\", \"No URL available\")\n",
    "        venue = paper.get(\"venue\", \"Unknown venue\")\n",
    "        results.append(\n",
    "            f\"Title: {title}\\nVenue: {venue}\\nAbstract: {abstract}\\nURL: {paper_url}\\n\"\n",
    "        )\n",
    "    \n",
    "    return \"\\n\".join(results)\n",
    "\n",
    "# Wrap the function as a LangChain Tool.\n",
    "informs_tool = Tool(\n",
    "    name=\"INFORMSJournalSearch\",\n",
    "    func=informs_journal_search,\n",
    "    description=(\"Searches for academic papers using Semantic Scholar and filters the results \"\n",
    "                 \"to only include papers published in INFORMS journals (e.g., Operations Research, \"\n",
    "                 \"Management Science, MSOM, and related outlets).\")\n",
    ")\n",
    "\n",
    "# --- Step 2: Initialize the LangChain Agent with the Custom Tool ---\n",
    "llm = OpenAI(temperature=0)\n",
    "agent = initialize_agent(\n",
    "    tools=[informs_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "# --- Step 3: Query the Agent ---\n",
    "# Example query: find INFORMS journal papers on operations research, management science, or MSOM related to bike lanes planning.\n",
    "topic_query = (\"Find academic papers on operations research, management science, and MSOM published in INFORMS journals \"\n",
    "               \"that are relevant to bike lanes planning. Please provide a summary of key findings and the venue of each paper.\")\n",
    "result = agent.run(topic_query)\n",
    "\n",
    "print(\"\\n=== INFORMS Journal Search Result ===\\n\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Task: Literature review bot\n",
    "This bot is operated by 3 agents. The first agent extracts keywords from a PDF document. The keywords would then be passed to the second agent who searches relevant papers online. The third agent will compare and contrast the PDF document and the papers found by the second agent and output a literature review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Agent 1: Extracted Keywords ===\n",
      "urban bike lane design, multi-objective optimization, safety and traffic efficiency\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lb/_r77cfp52216j6zh_x2jdhk00000gn/T/ipykernel_53770/1432617418.py:46: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  for result in search.results():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Agent 2: arXiv Paper Search Results ===\n",
      "\n",
      "================================================================================\n",
      "\n",
      "=== Agent 3: Literature Review ===\n",
      " In this literature review, I will compare our paper with some of the related work, highlighting similarities, differences, and trends.\n",
      "\n",
      "One of the key themes that emerged from my search is the use of multi-objective optimization in urban bike lane design. This approach aims to find the best possible solution that balances multiple objectives, such as safety and traffic efficiency. Our paper also utilizes this approach, using a genetic algorithm to optimize the design of bike lanes in urban areas. This is similar to the work of Li et al. (2019), who also used a genetic algorithm to optimize bike lane design for safety and efficiency. However, our paper differs in that we also consider the impact of bike lane design on other modes of transportation, such as pedestrians and cars, which is not explicitly addressed in Li et al.'s study.\n",
      "\n",
      "Another common theme in the literature is the consideration of safety in bike lane design. This is a crucial aspect, as the safety of cyclists is a major concern in urban areas. Our paper addresses this by incorporating safety metrics, such as the number of conflicts between cyclists and other modes of transportation, into the optimization process. This is similar to the work of Chen et al. (2018), who also used safety metrics in their optimization model for bike lane design. However, our paper differs in that we also consider the impact of bike lane design on traffic efficiency, which is not explicitly addressed in Chen et al.'s study.\n",
      "\n",
      "In terms of trends, there is a growing focus on incorporating data-driven approaches in urban bike lane design. This is evident in the work of Li et al. (2019), who used data from GPS trackers to analyze the behavior of cyclists and inform their optimization model. Our paper also utilizes data, such as traffic volume and speed, to inform the design of bike lanes. This trend towards data-driven approaches highlights the importance of using empirical evidence to inform decision-making in urban planning.\n",
      "\n",
      "Another trend in the literature is the consideration of different types of bike lanes, such as protected bike lanes and shared lanes. Our paper also considers these different types of bike lanes and their impact on safety and traffic efficiency. This is similar to the work of Chen et al. (2018), who also compared the safety and efficiency of different types of bike lanes. However, our paper differs in that we also consider the impact of bike lane design on other modes of transportation, which is not explicitly addressed in Chen et al.'s study.\n",
      "\n",
      "In conclusion, our paper contributes to the existing literature by incorporating a multi-objective optimization approach that considers the impact of bike lane design on safety, traffic efficiency, and other modes of transportation. It also aligns with current trends in the field, such as the use of data-driven approaches and the consideration of different types of bike lanes. However, further research is needed to fully understand the complex interactions between bike lane design, safety, and traffic efficiency in urban areas. \n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------\n",
    "# Agent 1: PDF Reader - Extracts three keywords\n",
    "# --------------------------------------------------\n",
    "def extract_keywords_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Loads a PDF file from the given path, extracts its text, \n",
    "    and outputs three keywords that best summarize the paper, \n",
    "    separated by commas.\n",
    "    \"\"\"\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    documents = loader.load()\n",
    "    full_text = \"\\n\".join([doc.page_content for doc in documents])\n",
    "    \n",
    "    prompt = (\n",
    "        \"You are an academic expert. Read the following research paper content and \"\n",
    "        \"extract three keywords that best summarize the paper. \"\n",
    "        \"Return only the three keywords separated by commas.\\n\\n\"\n",
    "        f\"{full_text}\\n\\n\"\n",
    "        \"Three keywords:\"\n",
    "    )\n",
    "    \n",
    "    # Increased max_tokens to allow for a longer response if needed\n",
    "    llm_local = OpenAI(\n",
    "        temperature=0,\n",
    "        max_tokens=500,  # Increase as needed\n",
    "        # model_name=\"gpt-3.5-turbo-16k\"  # Uncomment if you have access to the 16k model\n",
    "    )\n",
    "    keywords = llm_local.predict(prompt)\n",
    "    return keywords.strip()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Agent 2: arXiv Paper Searcher\n",
    "# --------------------------------------------------\n",
    "def search_arxiv_papers(query: str, max_results: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Searches arXiv for academic papers relevant to the given query.\n",
    "    Returns a formatted string with the title, authors, summary, \n",
    "    publication date, and URL of each paper.\n",
    "    \"\"\"\n",
    "    search = arxiv.Search(\n",
    "        query=query,\n",
    "        max_results=max_results,\n",
    "        sort_by=arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "    results = []\n",
    "    for result in search.results():\n",
    "        authors = \", \".join(author.name for author in result.authors)\n",
    "        results.append(\n",
    "            f\"Title: {result.title}\\n\"\n",
    "            f\"Authors: {authors}\\n\"\n",
    "            f\"Summary: {result.summary}\\n\"\n",
    "            f\"Published: {result.published.date()}\\n\"\n",
    "            f\"URL: {result.entry_id}\\n\"\n",
    "        )\n",
    "    if not results:\n",
    "        return \"No papers found for this query on arXiv.\"\n",
    "    return \"\\n\".join(results)\n",
    "\n",
    "# Wrap the search function as a LangChain Tool\n",
    "arxiv_search_tool = Tool(\n",
    "    name=\"arXivPaperSearch\",\n",
    "    func=search_arxiv_papers,\n",
    "    description=(\n",
    "        \"Searches for academic papers on arXiv based on a given query. \"\n",
    "        \"Input should be a set of keywords (connected with OR) that capture the topics of interest.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Build a LangChain agent that can use the above Tool\n",
    "agent_arxiv = initialize_agent(\n",
    "    tools=[arxiv_search_tool],\n",
    "    llm=OpenAI(\n",
    "        temperature=0,\n",
    "        max_tokens=500,  # Increase as needed\n",
    "        # model_name=\"gpt-3.5-turbo-16k\"  # Uncomment if you have access to the 16k model\n",
    "    ),\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Agent 3: Literature Reviewer\n",
    "# --------------------------------------------------\n",
    "def generate_literature_review(paper_keywords: str, search_results: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates a literature review by comparing the extracted keywords from our paper \n",
    "    with the search results from arXiv. The review should be less than 500 words.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        \"You are an academic expert. Using the keywords and arXiv results below, \"\n",
    "        \"write a literature review that compares our paper with related work, \"\n",
    "        \"highlighting similarities, differences, and trends. Keep the review under 500 words.\\n\\n\"\n",
    "        f\"Keywords: {paper_keywords}\\n\\n\"\n",
    "        f\"Search Results: {search_results}\"\n",
    "    )\n",
    "\n",
    "    llm_local = OpenAI(\n",
    "        temperature=0,\n",
    "        max_tokens=600,  # Allow enough tokens for the full review\n",
    "        # model_name=\"gpt-3.5-turbo-16k\"  # Uncomment if you have access\n",
    "    )\n",
    "    review = llm_local.predict(prompt)\n",
    "    return review\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Main Pipeline: Chain the Three Agents\n",
    "# --------------------------------------------------\n",
    "# (Remove if __name__ == \"__main__\": for notebook use)\n",
    "\n",
    "# 1) Extract keywords from the local PDF\n",
    "pdf_path = \"Abstract 1.pdf\"  # Replace with your actual PDF\n",
    "paper_keywords = extract_keywords_from_pdf(pdf_path)\n",
    "print(\"=== Agent 1: Extracted Keywords ===\")\n",
    "print(paper_keywords)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# 2) Use those keywords to search arXiv\n",
    "keywords_list = [kw.strip() for kw in paper_keywords.split(\",\") if kw.strip()]\n",
    "search_query = \" OR \".join(keywords_list)\n",
    "search_results = agent_arxiv.run(search_query)\n",
    "print(\"=== Agent 2: arXiv Paper Search Results ===\")\n",
    "# You may ask the code to report the search results if you have enough tokens.\n",
    "# print(search_results) \n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# 3) Generate a literature review\n",
    "literature_review = generate_literature_review(paper_keywords, search_results)\n",
    "print(\"=== Agent 3: Literature Review ===\")\n",
    "print(literature_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
